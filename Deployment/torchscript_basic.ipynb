{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "introduction to torchscript.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('introduction to torchscript.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1.2.0\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "basics of pytorch model authoring\n",
      "(tensor([[0.8584, 0.8193, 0.8820, 0.9504],\n        [0.7409, 0.8393, 0.7489, 0.7216],\n        [0.6857, 0.4367, 0.0745, 0.7348]]), tensor([[0.8584, 0.8193, 0.8820, 0.9504],\n        [0.7409, 0.8393, 0.7489, 0.7216],\n        [0.6857, 0.4367, 0.0745, 0.7348]]))\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('basics of pytorch model authoring')\n",
    "class MyCell(torch.nn.Module):\n",
    "    def __init(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(x + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell = MyCell()\n",
    "x = torch.rand(3, 4)\n",
    "h = torch.rand(3, 4)\n",
    "print(my_cell(x, h))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "MyCell(\n  (linear): Linear(in_features=4, out_features=4, bias=True)\n)\n(tensor([[ 0.1761,  0.6880,  0.6352,  0.7515],\n        [-0.1975,  0.9413,  0.8519,  0.5038],\n        [-0.1288,  0.7946,  0.7693,  0.8332]], grad_fn=<TanhBackward>), tensor([[ 0.1761,  0.6880,  0.6352,  0.7515],\n        [-0.1975,  0.9413,  0.8519,  0.5038],\n        [-0.1288,  0.7946,  0.7693,  0.8332]], grad_fn=<TanhBackward>))\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.linear(x) + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell = MyCell()\n",
    "print(my_cell)\n",
    "print(my_cell(x, h))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "MyCell(\n  (dg): MyDecisionGate()\n  (linear): Linear(in_features=4, out_features=4, bias=True)\n)\n(tensor([[ 0.8152, -0.2037,  0.4657,  0.6881],\n        [ 0.4889,  0.5876,  0.8306,  0.2261],\n        [ 0.7118, -0.2396,  0.6319,  0.7876]], grad_fn=<TanhBackward>), tensor([[ 0.8152, -0.2037,  0.4657,  0.6881],\n        [ 0.4889,  0.5876,  0.8306,  0.2261],\n        [ 0.7118, -0.2396,  0.6319,  0.7876]], grad_fn=<TanhBackward>))\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "class MyDecisionGate(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        if x.sum() > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return -x\n",
    "\n",
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.dg = MyDecisionGate()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        return new_h, new_h\n",
    "    \n",
    "my_cell = MyCell()\n",
    "print(my_cell)\n",
    "print(my_cell(x, h))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tracing...\nTracedModule[MyCell](\n  (linear): TracedModule[Linear]()\n)\n(tensor([[ 0.8107,  0.6864, -0.0111, -0.0114],\n        [ 0.8867,  0.5783, -0.3450,  0.6337],\n        [ 0.9471,  0.4010, -0.1775,  0.4589]],\n       grad_fn=<DifferentiableGraphBackward>), tensor([[ 0.8107,  0.6864, -0.0111, -0.0114],\n        [ 0.8867,  0.5783, -0.3450,  0.6337],\n        [ 0.9471,  0.4010, -0.1775,  0.4589]],\n       grad_fn=<DifferentiableGraphBackward>))\ngraph(%self : ClassType<MyCell>,\n      %input : Float(3, 4),\n      %h : Float(3, 4)):\n  %1 : ClassType<Linear> = prim::GetAttr[name=\"linear\"](%self)\n  %weight : Tensor = prim::GetAttr[name=\"weight\"](%1)\n  %bias : Tensor = prim::GetAttr[name=\"bias\"](%1)\n  %6 : Float(4!, 4!) = aten::t(%weight), scope: MyCell/Linear[linear] # /home/rong/PycharmProjects/PyTorchTutorals/venv/lib/python3.6/site-packages/torch/nn/functional.py:1369:0\n  %7 : int = prim::Constant[value=1](), scope: MyCell/Linear[linear] # /home/rong/PycharmProjects/PyTorchTutorals/venv/lib/python3.6/site-packages/torch/nn/functional.py:1369:0\n  %8 : int = prim::Constant[value=1](), scope: MyCell/Linear[linear] # /home/rong/PycharmProjects/PyTorchTutorals/venv/lib/python3.6/site-packages/torch/nn/functional.py:1369:0\n  %9 : Float(3, 4) = aten::addmm(%bias, %input, %6, %7, %8), scope: MyCell/Linear[linear] # /home/rong/PycharmProjects/PyTorchTutorals/venv/lib/python3.6/site-packages/torch/nn/functional.py:1369:0\n  %10 : int = prim::Constant[value=1](), scope: MyCell # <ipython-input-13-c2eeaa02d4fb>:8:0\n  %11 : Float(3, 4) = aten::add(%9, %h, %10), scope: MyCell # <ipython-input-13-c2eeaa02d4fb>:8:0\n  %12 : Float(3, 4) = aten::tanh(%11), scope: MyCell # <ipython-input-13-c2eeaa02d4fb>:8:0\n  %13 : (Float(3, 4), Float(3, 4)) = prim::TupleConstruct(%12, %12)\n  return (%13)\n\ndef forward(self,\n    input: Tensor,\n    h: Tensor) -> Tuple[Tensor, Tensor]:\n  _0 = self.linear\n  weight = _0.weight\n  bias = _0.bias\n  _1 = torch.addmm(bias, input, torch.t(weight), beta=1, alpha=1)\n  _2 = torch.tanh(torch.add(_1, h, alpha=1))\n  return (_2, _2)\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('tracing...')\n",
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.linear(x) + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell = MyCell()\n",
    "x, h = torch.rand(3,4), torch.rand(3,4)\n",
    "traced_cell = torch.jit.trace(my_cell, (x, h))\n",
    "print(traced_cell)\n",
    "print(traced_cell(x, h))\n",
    "print(traced_cell.graph)\n",
    "print(traced_cell.code)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "def forward(self,\n    input: Tensor,\n    h: Tensor) -> Tuple[Tensor, Tensor]:\n  _0 = self.linear\n  weight = _0.weight\n  bias = _0.bias\n  x = torch.addmm(bias, input, torch.t(weight), beta=1, alpha=1)\n  _1 = torch.tanh(torch.add(x, h, alpha=1))\n  return (_1, _1)\n\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/home/rong/PycharmProjects/PyTorchTutorals/venv/lib/python3.6/site-packages/ipykernel_launcher.py:3: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "class MyDecisionGate(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        if x.sum() > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return -x\n",
    "\n",
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self, dg):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.dg = dg\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        return new_h, new_h\n",
    "    \n",
    "my_cell = MyCell(MyDecisionGate())\n",
    "traced_cell = torch.jit.trace(my_cell, (x, h))\n",
    "# print(my_cell)\n",
    "# print(my_cell(x, h))\n",
    "print(traced_cell.code)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "def forward(self,\n    x: Tensor,\n    h: Tensor) -> Tuple[Tensor, Tensor]:\n  _0 = self.linear\n  _1 = _0.weight\n  _2 = _0.bias\n  if torch.eq(torch.dim(x), 2):\n    _3 = torch.__isnot__(_2, None)\n  else:\n    _3 = False\n  if _3:\n    bias = ops.prim.unchecked_unwrap_optional(_2)\n    ret = torch.addmm(bias, x, torch.t(_1), beta=1, alpha=1)\n  else:\n    output = torch.matmul(x, torch.t(_1))\n    if torch.__isnot__(_2, None):\n      bias0 = ops.prim.unchecked_unwrap_optional(_2)\n      output0 = torch.add_(output, bias0, alpha=1)\n    else:\n      output0 = output\n    ret = output0\n  _4 = torch.gt(torch.sum(ret, dtype=None), 0)\n  if bool(_4):\n    _5 = ret\n  else:\n    _5 = torch.neg(ret)\n  new_h = torch.tanh(torch.add(_5, h, alpha=1))\n  return (new_h, new_h)\n\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "(tensor([[ 0.9194,  0.8591,  0.2544,  0.0303],\n         [ 0.6037,  0.6210,  0.3884,  0.0590],\n         [ 0.7844,  0.8996,  0.5261, -0.2167]],\n        grad_fn=<DifferentiableGraphBackward>),\n tensor([[ 0.9194,  0.8591,  0.2544,  0.0303],\n         [ 0.6037,  0.6210,  0.3884,  0.0590],\n         [ 0.7844,  0.8996,  0.5261, -0.2167]],\n        grad_fn=<DifferentiableGraphBackward>))"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 19
    }
   ],
   "source": [
    "scripted_gate = torch.jit.script(MyDecisionGate())\n",
    "my_cell = MyCell(scripted_gate)\n",
    "traced_cell = torch.jit.script(my_cell)\n",
    "print(traced_cell.code)\n",
    "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
    "traced_cell(x, h)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Mixing scripting and tracing....\ndef forward(self,\n    xs: Tensor) -> Tuple[Tensor, Tensor]:\n  h = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)\n  y = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)\n  y0, h0 = y, h\n  for i in range(torch.size(xs, 0)):\n    _0 = self.cell\n    _1 = torch.select(xs, 0, i)\n    _2 = _0.linear\n    weight = _2.weight\n    bias = _2.bias\n    _3 = torch.addmm(bias, _1, torch.t(weight), beta=1, alpha=1)\n    _4 = torch.gt(torch.sum(_3, dtype=None), 0)\n    if bool(_4):\n      _5 = _3\n    else:\n      _5 = torch.neg(_3)\n    _6 = torch.tanh(torch.add(_5, h0, alpha=1))\n    y0, h0 = _6, _6\n  return (y0, h0)\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('Mixing scripting and tracing....')\n",
    "class MyRNNLoop(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyRNNLoop, self).__init__()\n",
    "        self.cell = torch.jit.trace(MyCell(scripted_gate), (x, h))\n",
    "    \n",
    "    def forward(self, xs):\n",
    "        h, y = torch.zeros(3, 4), torch.zeros(3, 4)\n",
    "        for i in range(xs.size(0)):\n",
    "            y, h = self.cell(xs[i], h)\n",
    "        return y, h\n",
    "    \n",
    "rnn_loop = torch.jit.script(MyRNNLoop())\n",
    "print(rnn_loop.code)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "def forward(self,\n    argument_1: Tensor) -> Tensor:\n  _0 = self.loop\n  h = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)\n  h0 = h\n  for i in range(torch.size(argument_1, 0)):\n    _1 = _0.cell\n    _2 = torch.select(argument_1, 0, i)\n    _3 = _1.linear\n    weight = _3.weight\n    bias = _3.bias\n    _4 = torch.addmm(bias, _2, torch.t(weight), beta=1, alpha=1)\n    _5 = torch.gt(torch.sum(_4, dtype=None), 0)\n    if bool(_5):\n      _6 = _4\n    else:\n      _6 = torch.neg(_4)\n    h0 = torch.tanh(torch.add(_6, h0, alpha=1))\n  return torch.relu(h0)\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "class WrapRNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WrapRNN, self).__init__()\n",
    "        self.loop = torch.jit.script(MyRNNLoop())\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        y, h = self.loop(xs)\n",
    "        return torch.relu(y)\n",
    "    \n",
    "traced = torch.jit.trace(WrapRNN(), (torch.rand(10, 3, 4)))\n",
    "print(traced.code)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Saving and Loading models\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('Saving and Loading models')\n",
    "traced.save('wrapped_rnn.zip')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ScriptModule(\n  (loop): ScriptModule(\n    (cell): ScriptModule(\n      (dg): ScriptModule()\n      (linear): ScriptModule()\n    )\n  )\n)\ndef forward(self,\n    argument_1: Tensor) -> Tensor:\n  _0 = self.loop\n  h = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)\n  h0 = h\n  for i in range(torch.size(argument_1, 0)):\n    _1 = _0.cell\n    _2 = torch.select(argument_1, 0, i)\n    _3 = _1.linear\n    weight = _3.weight\n    bias = _3.bias\n    _4 = torch.addmm(bias, _2, torch.t(weight), beta=1, alpha=1)\n    _5 = torch.gt(torch.sum(_4, dtype=None), 0)\n    if bool(_5):\n      _6 = _4\n    else:\n      _6 = torch.neg(_4)\n    h0 = torch.tanh(torch.add(_6, h0, alpha=1))\n  return torch.relu(h0)\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "loaded = torch.jit.load('wrapped_rnn.zip')\n",
    "print(loaded)\n",
    "print(loaded.code)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (PyTorchTutorals)",
   "language": "python",
   "name": "pycharm-12c6a786"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
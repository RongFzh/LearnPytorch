{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% 使用nn.Module实现 AlexNet\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "AlexNet！！\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('AlexNet！！')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import CIFAR10\n",
    "%matplotlib inline\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 第一层 5x5卷积， 输入channel是3， 输出channel是64，步长是1，没有padding\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 5),\n",
    "            nn.ReLU(True))\n",
    "        \n",
    "        # 第二层是 3x3的池化， 步长是2， 没有padding\n",
    "        self.max_pool1 = nn.MaxPool2d(3, 2)\n",
    "        \n",
    "        # 第三层是 5x5的卷积， 输入channel 64， 输出channel 64， 步长1， 没有padding\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 5, 1),\n",
    "            nn.ReLU(True))\n",
    "        \n",
    "        # 第四层是3x3的池化，步长是2，没有padding\n",
    "        self.max_pool2 = nn.MaxPool2d(3, 2)\n",
    "        \n",
    "        # 第五层是全连接层， 输入是1204， 输出是384\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(1024, 384), \n",
    "            nn.ReLU(True))\n",
    "\n",
    "        # 第六层是全连接层， 输入是384， 输出是192\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(384, 192),\n",
    "            nn.ReLU(True))\n",
    "        \n",
    "        # 第六层是全连接层， 输入是384， 输出是192\n",
    "        self.fc3 = nn.Linear(192, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        print('conv1(x) output: {}x{}'.format(x.shape[2], x.shape[3]))\n",
    "        x = self.max_pool1(x)\n",
    "        print('max_pool1(x) output: {}x{}'.format(x.shape[2], x.shape[3]))\n",
    "        x = self.conv2(x)\n",
    "        print('conv2(x) output: {}x{}'.format(x.shape[2], x.shape[3]))\n",
    "        x = self.max_pool2(x)\n",
    "        print('max_pool2(x) output: {}x{}'.format(x.shape[2], x.shape[3]))\n",
    "        \n",
    "        x = x.view(x.shape[0],-1)\n",
    "        print('x shape after view:')\n",
    "        print(x.shape)\n",
    "        print('view(x) output: {}x{}'.format(x.shape[0], x.shape[1]))\n",
    "        x = self.fc1(x)\n",
    "        print('fc1(x) output: {}x{}'.format(x.shape[0], x.shape[1]))\n",
    "        x = self.fc2(x)\n",
    "        print('fc2(x) output: {}x{}'.format(x.shape[0], x.shape[1]))\n",
    "        x = self.fc3(x)\n",
    "        print('fc3(x) output: {}x{}'.format(x.shape[0], x.shape[1]))\n",
    "        \n",
    "        return x\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "AlexNet(\n  (conv1): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n    (1): ReLU(inplace)\n  )\n  (max_pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Sequential(\n    (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n    (1): ReLU(inplace)\n  )\n  (max_pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (fc1): Sequential(\n    (0): Linear(in_features=1024, out_features=384, bias=True)\n    (1): ReLU(inplace)\n  )\n  (fc2): Sequential(\n    (0): Linear(in_features=384, out_features=192, bias=True)\n    (1): ReLU(inplace)\n  )\n  (fc3): Linear(in_features=192, out_features=10, bias=True)\n)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "alexnet = AlexNet()\n",
    "alexnet\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "conv1(x) output: 28x28\nmax_pool1(x) output: 13x13\nconv2(x) output: 9x9\nmax_pool2(x) output: 4x4\nx shape after view:\ntorch.Size([1, 1024])\nview(x) output: 1x1024\nfc1(x) output: 1x384\nfc2(x) output: 1x192\nfc3(x) output: 1x10\ntorch.Size([1, 10])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "input_demo = Variable(torch.zeros(1, 3, 32, 32))\n",
    "output_demo = alexnet(input_demo)\n",
    "print(output_demo.shape)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% 定义输入(1, 3, 32, 32)\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "torch.Size([128, 30])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "m = nn.Linear(20, 30)\n",
    "input = torch.randn(128, 20)\n",
    "output = m(input)\n",
    "print(output.size())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "pycharm-12c6a786",
   "language": "python",
   "display_name": "PyCharm (PyTorchTutorals)"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "批标准化\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('批标准化')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 一维的情况\n",
    "import torch\n",
    "def simple_batch_norm_1d(x, gamma, beta):\n",
    "    eps = 1e-5\n",
    "    x_mean = torch.mean(x, dim=0, keepdim=True)\n",
    "    x_var = torch.mean((x-x_mean)**2, dim=0, keepdim=True)\n",
    "    x_hat = (x - x_mean) / torch.sqrt(x_var + eps)\n",
    "    return gamma.view_as(x_mean) * x_hat + beta.view_as(x_mean)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "before bn:",
      "\n",
      "tensor([[ 0.,  1.,  2.],\n        [ 3.,  4.,  5.],\n        [ 6.,  7.,  8.],\n        [ 9., 10., 11.],\n        [12., 13., 14.]])",
      "\n",
      "after bn:",
      "\n",
      "tensor([[-1.4142, -1.4142, -1.4142],\n        [-0.7071, -0.7071, -0.7071],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.7071,  0.7071,  0.7071],\n        [ 1.4142,  1.4142,  1.4142]])",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x = torch.arange(15).view(5, 3).to(torch.float)\n",
    "gamma = torch.ones(x.shape[1])\n",
    "beta = torch.zeros(x.shape[1])\n",
    "print('before bn:')\n",
    "print(x)\n",
    "y = simple_batch_norm_1d(x, gamma, beta)\n",
    "print('after bn:')\n",
    "print(y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "torch.Size([5, 3])",
      "\n",
      "torch.Size([1, 3])",
      "\n",
      "torch.Size([1, 3])",
      "\n",
      "torch.Size([1, 3])",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(x.shape)\n",
    "x_m = torch.mean(x, dim=0, keepdim=True)\n",
    "print(x_m.shape)\n",
    "x_v = torch.mean((x-x_m)**2, dim=0, keepdim=True)\n",
    "print(x_v.shape)\n",
    "print(gamma.view_as(x_m).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# 能够区分训练状态和测试状态的批标准化方法\n",
    "def batch_norm_1d(x, gamma, beta, is_training, moving_mean, moving_var, moving_momentum=0.1):\n",
    "    eps = 1e-5\n",
    "    x_mean = torch.mean(x, dim=0, keepdim=True) # 保留维度进行broadcast\n",
    "    x_var = torch.mean((x - x_mean) ** 2, dim=0, keepdim=True)\n",
    "    if is_training:\n",
    "        x_hat = (x - x_mean) / torch.sqrt(x_var + eps)\n",
    "        moving_mean[:] = moving_momentum * moving_mean + (1. - moving_momentum) * x_mean.cpu()\n",
    "        moving_var[:] = moving_momentum * moving_var + (1. - moving_momentum) * x_var.cpu()\n",
    "    else:\n",
    "        x_hat = (x - moving_mean) / torch.sqrt(moving_var + eps)\n",
    "    return gamma.view_as(x_mean) * x_hat + beta.view_as(x_mean)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# 用MNIST验证是否可用\n",
    "import numpy as np\n",
    "from torchvision.datasets import mnist\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# 使用内置函数下载MNIST数据集\n",
    "train_set = mnist.MNIST('../data', train=True)\n",
    "test_set = mnist.MNIST('../data', train=False)\n",
    "\n",
    "def data_tf(x):\n",
    "    x = np.array(x, dtype='float32') / 255\n",
    "    x = (x - 0.5) / 0.5\n",
    "    x = x.reshape((-1,))\n",
    "    x = torch.from_numpy(x)\n",
    "    return x\n",
    "\n",
    "train_set = mnist.MNIST('../data', train=True, transform=data_tf, download=True)\n",
    "test_set = mnist.MNIST('../data', train=False, transform=data_tf, download=True)\n",
    "train_data = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_data = DataLoader(test_set, batch_size=32, shuffle=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "class multi_network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(multi_network, self).__init__()\n",
    "        self.layer1 = nn.Linear(784, 100)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.layer2 = nn.Linear(100, 10)\n",
    "        \n",
    "        self.gamma = nn.Parameter(torch.randn(100))\n",
    "        self.beta = nn.Parameter(torch.randn(100))\n",
    "        \n",
    "        self.moving_mean = Variable(torch.zeros(100))\n",
    "        self.moving_var = Variable(torch.zeros(100))\n",
    "        \n",
    "    def forward(self, x, is_train=True):\n",
    "        x = self.layer1(x)\n",
    "        x = batch_norm_1d(x, self.gamma, self.beta, is_train, self.moving_mean, self.moving_var)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch 0. Train Loss: 0.300847, Train Acc: 0.911950, Valid Loss: 0.188840, Valid Acc: 0.943890, Time 00:00:26",
      "\n",
      "Epoch 1. Train Loss: 0.168357, Train Acc: 0.949817, Valid Loss: 0.148208, Valid Acc: 0.956769, Time 00:00:30",
      "\n",
      "Epoch 2. Train Loss: 0.131344, Train Acc: 0.960033, Valid Loss: 0.130643, Valid Acc: 0.961861, Time 00:00:31",
      "\n",
      "Epoch 3. Train Loss: 0.110123, Train Acc: 0.966550, Valid Loss: 0.125073, Valid Acc: 0.960563, Time 00:00:34",
      "\n",
      "Epoch 4. Train Loss: 0.093588, Train Acc: 0.971133, Valid Loss: 0.120028, Valid Acc: 0.963159, Time 00:00:37",
      "\n",
      "Epoch 5. Train Loss: 0.083763, Train Acc: 0.974333, Valid Loss: 0.111815, Valid Acc: 0.966753, Time 00:00:38",
      "\n",
      "Epoch 6. Train Loss: 0.075459, Train Acc: 0.976283, Valid Loss: 0.109438, Valid Acc: 0.967552, Time 00:00:37",
      "\n",
      "Epoch 7. Train Loss: 0.069377, Train Acc: 0.978217, Valid Loss: 0.105319, Valid Acc: 0.967552, Time 00:00:39",
      "\n",
      "Epoch 8. Train Loss: 0.065798, Train Acc: 0.979300, Valid Loss: 0.108963, Valid Acc: 0.967652, Time 00:00:40",
      "\n",
      "Epoch 9. Train Loss: 0.060953, Train Acc: 0.980133, Valid Loss: 0.105625, Valid Acc: 0.968650, Time 00:00:42",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 训练\n",
    "net = multi_network()\n",
    "# loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), 1e-1)\n",
    "from C5_CNN.utils import train\n",
    "train(net, train_data, test_data, 10, optimizer, criterion)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([-3.3059, -0.6155,  0.0912, -0.3872,  5.9877,  3.4052,  0.5311,  0.1161,\n        -3.1937,  0.6356], grad_fn=<SliceBackward>)",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(net.moving_mean[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch 0. Train Loss: 0.366584, Train Acc: 0.882483, Valid Loss: 0.163591, Valid Acc: 0.948782, Time 00:00:20",
      "\n",
      "Epoch 1. Train Loss: 0.173393, Train Acc: 0.946367, Valid Loss: 0.148600, Valid Acc: 0.953175, Time 00:00:23",
      "\n",
      "Epoch 2. Train Loss: 0.134626, Train Acc: 0.958833, Valid Loss: 0.144682, Valid Acc: 0.956569, Time 00:00:26",
      "\n",
      "Epoch 3. Train Loss: 0.116492, Train Acc: 0.963867, Valid Loss: 0.150574, Valid Acc: 0.956170, Time 00:00:25",
      "\n",
      "Epoch 4. Train Loss: 0.100459, Train Acc: 0.968517, Valid Loss: 0.122538, Valid Acc: 0.964357, Time 00:00:25",
      "\n",
      "Epoch 5. Train Loss: 0.091769, Train Acc: 0.971233, Valid Loss: 0.132585, Valid Acc: 0.962260, Time 00:00:24",
      "\n",
      "Epoch 6. Train Loss: 0.082237, Train Acc: 0.973750, Valid Loss: 0.125345, Valid Acc: 0.962260, Time 00:00:24",
      "\n",
      "Epoch 7. Train Loss: 0.077787, Train Acc: 0.975967, Valid Loss: 0.103685, Valid Acc: 0.971046, Time 00:00:24",
      "\n",
      "Epoch 8. Train Loss: 0.070292, Train Acc: 0.977117, Valid Loss: 0.102938, Valid Acc: 0.969948, Time 00:00:24",
      "\n",
      "Epoch 9. Train Loss: 0.066449, Train Acc: 0.978483, Valid Loss: 0.115485, Valid Acc: 0.965855, Time 00:00:25",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 不用批标准化的结果\n",
    "no_bn_net = nn.Sequential(\n",
    "    nn.Linear(784, 100),\n",
    "    nn.ReLU(True),\n",
    "    nn.Linear(100, 10)\n",
    ")\n",
    "optimizer = torch.optim.SGD(no_bn_net.parameters(), 1e-1)\n",
    "train(no_bn_net, train_data, test_data, 10, optimizer, criterion)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch 0. Train Loss: 0.130878, Train Acc: 0.961333, Valid Loss: 0.093079, Valid Acc: 0.970647, Time 00:00:50",
      "\n",
      "Epoch 1. Train Loss: 0.053629, Train Acc: 0.983500, Valid Loss: 0.039332, Valid Acc: 0.986222, Time 00:00:51",
      "\n",
      "Epoch 2. Train Loss: 0.041747, Train Acc: 0.987200, Valid Loss: 0.039187, Valid Acc: 0.987220, Time 00:00:50",
      "\n",
      "Epoch 3. Train Loss: 0.035006, Train Acc: 0.988600, Valid Loss: 0.035332, Valid Acc: 0.989117, Time 00:00:49",
      "\n",
      "Epoch 4. Train Loss: 0.030113, Train Acc: 0.990417, Valid Loss: 0.043766, Valid Acc: 0.986621, Time 00:00:48",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 卷积网络 批标准化 用pytorch自带的批标准化函数\n",
    "def data_tf(x):\n",
    "    x = np.array(x, dtype='float32') / 255\n",
    "    x = (x - 0.5) / 0.5\n",
    "    x = torch.from_numpy(x)\n",
    "    x = x.unsqueeze(0)\n",
    "    return x\n",
    "\n",
    "train_set = mnist.MNIST('../data', train=True, transform=data_tf, download=True)\n",
    "test_set = mnist.MNIST('../data', train=False, transform=data_tf, download=True)\n",
    "train_data = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_data = DataLoader(test_set, batch_size=32, shuffle=False)\n",
    "\n",
    "# 使用批标准化\n",
    "class conv_bn_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(conv_bn_net, self).__init__()\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 3, padding=1),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.classify = nn.Linear(400, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.stage1(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.classify(x)\n",
    "        return x\n",
    "\n",
    "net = conv_bn_net()\n",
    "optimizer = torch.optim.SGD(net.parameters(), 1e-1)\n",
    "train(net, train_data, test_data, 5, optimizer, criterion)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch 0. Train Loss: 0.174324, Train Acc: 0.944900, Valid Loss: 0.065926, Valid Acc: 0.977736, Time 00:00:35",
      "\n",
      "Epoch 1. Train Loss: 0.064510, Train Acc: 0.979967, Valid Loss: 0.049920, Valid Acc: 0.984125, Time 00:00:39",
      "\n",
      "Epoch 2. Train Loss: 0.049106, Train Acc: 0.984950, Valid Loss: 0.053070, Valid Acc: 0.983227, Time 00:00:38",
      "\n",
      "Epoch 3. Train Loss: 0.042375, Train Acc: 0.986967, Valid Loss: 0.050653, Valid Acc: 0.983926, Time 00:00:38",
      "\n",
      "Epoch 4. Train Loss: 0.036420, Train Acc: 0.988133, Valid Loss: 0.052674, Valid Acc: 0.982328, Time 00:00:38",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 不使用批标准化\n",
    "class conv_no_bn_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(conv_no_bn_net, self).__init__()\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 3, padding=1),\n",
    "            # nn.BatchNorm2d(6),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            #nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.classify = nn.Linear(400, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.stage1(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.classify(x)\n",
    "        return x\n",
    "\n",
    "net = conv_no_bn_net()\n",
    "optimizer = torch.optim.SGD(net.parameters(), 1e-1)\n",
    "train(net, train_data, test_data, 5, optimizer, criterion)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
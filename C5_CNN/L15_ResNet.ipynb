{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import CIFAR10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def conv3x3(in_channel, out_channel, stride=1):\n",
    "    return nn.Conv2d(in_channel, out_channel, 3, stride=stride, padding=1, bias=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class residual_block(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, same_shape=True):\n",
    "        super(residual_block, self).__init__()\n",
    "        self.same_shape = same_shape\n",
    "        stride = 1 if self.same_shape else 2\n",
    "        \n",
    "        self.conv1 = conv3x3(in_channel, out_channel, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        \n",
    "        self.conv2 = conv3x3(out_channel, out_channel)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "        if not self.same_shape:\n",
    "            self.conv3 = nn.Conv2d(in_channel, out_channel, 1, stride=stride)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(self.bn1(out), True)\n",
    "        out = self.conv2(out)\n",
    "        out = F.relu(self.bn2(out), True)\n",
    "        \n",
    "        if not self.same_shape:\n",
    "            x = self.conv3(x)\n",
    "        \n",
    "        return F.relu(x+out, True)\n",
    "    \n",
    "\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "input: torch.Size([1, 32, 96, 96])\n",
      "output: torch.Size([1, 32, 96, 96])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 输入输出形状相同\n",
    "test_net = residual_block(32, 32)\n",
    "test_x = Variable(torch.zeros(1, 32, 96, 96))\n",
    "print('input: {}'.format(test_x.shape))\n",
    "test_y = test_net(test_x)\n",
    "print('output: {}'.format(test_y.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "input: torch.Size([1, 3, 96, 96])\noutput: torch.Size([1, 32, 48, 48])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 输入输出形状不同\n",
    "test_net = residual_block(3, 32, False)\n",
    "test_x = Variable(torch.zeros(1, 3, 96, 96))\n",
    "print('input: {}'.format(test_x.shape))\n",
    "test_y = test_net(test_x)\n",
    "print('output: {}'.format(test_y.shape))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class resnet(nn.Module):\n",
    "    def __init__(self, in_channel, num_classes, verbose=False):\n",
    "        super(resnet, self).__init__()\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.block1 = nn.Conv2d(in_channel, 64, 7, 2)\n",
    "        \n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            residual_block(64, 64),\n",
    "            residual_block(64, 64)\n",
    "        )\n",
    "        \n",
    "        self.block3 = nn.Sequential(\n",
    "            residual_block(64, 128, False),\n",
    "            residual_block(128, 128)\n",
    "        )\n",
    "        \n",
    "        self.block4 = nn.Sequential(\n",
    "            residual_block(128, 256, False),\n",
    "            residual_block(256, 256)\n",
    "        )\n",
    "        \n",
    "        self.block5 = nn.Sequential(\n",
    "            residual_block(256, 512, False),\n",
    "            residual_block(512, 512),\n",
    "            nn.AvgPool2d(3)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        if self.verbose:\n",
    "            print('block 1 output: {}'.format(x.shape))\n",
    "            \n",
    "        x = self.block2(x)\n",
    "        if self.verbose:\n",
    "            print('block 2 output: {}'.format(x.shape))\n",
    "            \n",
    "        x = self.block3(x)\n",
    "        if self.verbose:\n",
    "            print('block 3 output: {}'.format(x.shape))\n",
    "            \n",
    "        x = self.block4(x)\n",
    "        if self.verbose:\n",
    "            print('block 4 output: {}'.format(x.shape))\n",
    "                \n",
    "        x = self.block5(x)\n",
    "        if self.verbose:\n",
    "            print('block 5 output: {}'.format(x.shape))\n",
    "                \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        if self.verbose:\n",
    "            print('view output: {}'.format(x.shape))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% 实现一个ResNet\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "block 1 output: torch.Size([1, 64, 45, 45])\nblock 2 output: torch.Size([1, 64, 22, 22])\nblock 3 output: torch.Size([1, 128, 11, 11])\nblock 4 output: torch.Size([1, 256, 6, 6])\nblock 5 output: torch.Size([1, 512, 1, 1])\nview output: torch.Size([1, 512])\noutput: torch.Size([1, 10])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "test_net = resnet(3, 10, True)\n",
    "test_x = Variable(torch.zeros(1, 3, 96, 96))\n",
    "test_y = test_net(test_x)\n",
    "print('output: {}'.format(test_y.shape))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch 0. Train Loss: 1.375469, Train Acc: 0.500000, Valid Loss: 1.082369, Valid Acc: 0.615315, Time 00:01:33\n",
      "Epoch 1. Train Loss: 0.933724, Train Acc: 0.671145, Valid Loss: 0.910223, Valid Acc: 0.675319, Time 00:01:40\n",
      "Epoch 2. Train Loss: 0.711821, Train Acc: 0.751599, Valid Loss: 0.902322, Valid Acc: 0.698582, Time 00:01:41\n",
      "Epoch 3. Train Loss: 0.562391, Train Acc: 0.806202, Valid Loss: 0.893157, Valid Acc: 0.706869, Time 00:01:41\n",
      "Epoch 4. Train Loss: 0.435390, Train Acc: 0.849988, Valid Loss: 0.703638, Valid Acc: 0.766074, Time 00:01:39\n",
      "Epoch 5. Train Loss: 0.332899, Train Acc: 0.885117, Valid Loss: 0.905886, Valid Acc: 0.719249, Time 00:01:39\n",
      "Epoch 6. Train Loss: 0.244323, Train Acc: 0.916487, Valid Loss: 0.854152, Valid Acc: 0.741314, Time 00:01:41\n",
      "Epoch 7. Train Loss: 0.181166, Train Acc: 0.939079, Valid Loss: 0.928718, Valid Acc: 0.744708, Time 00:01:41\n",
      "Epoch 8. Train Loss: 0.137261, Train Acc: 0.952875, Valid Loss: 0.816203, Valid Acc: 0.771865, Time 00:01:41\n",
      "Epoch 9. Train Loss: 0.100100, Train Acc: 0.967190, Valid Loss: 0.887014, Valid Acc: 0.772264, Time 00:01:39\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 开始训练\n",
    "from C5_CNN.utils import train\n",
    "def data_tf(x):\n",
    "    x = x.resize((96, 96), 2)\n",
    "    x = np.array(x, dtype='float32') / 255\n",
    "    x = (x - 0.5) / 0.5\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x)\n",
    "    return x\n",
    "\n",
    "train_set = CIFAR10('../data', train=True, transform=data_tf)\n",
    "train_data = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_set = CIFAR10('../data', train=False, transform=data_tf)\n",
    "test_data = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=False)\n",
    "\n",
    "net = resnet(3, 10)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train(net, train_data, test_data, 10, optimizer, criterion)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "pycharm-12c6a786",
   "language": "python",
   "display_name": "PyCharm (PyTorchTutorals)"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}